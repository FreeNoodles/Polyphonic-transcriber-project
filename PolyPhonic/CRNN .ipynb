{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.losses import categorical_crossentropy,binary_crossentropy\n",
    "from keras.optimizers import RMSprop, rmsprop\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.activations import relu,sigmoid\n",
    "import urllib.request\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv \n",
    "import pandas as pd\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_labels_training = r\"D:\\PolyPhonic\\data\\training\\labels.csv\"\n",
    "# path_directory_training = r\"D:\\PolyPhonic\\data\\training\\images\"\n",
    "# path_directory_test = r\"D:\\PolyPhonic\\data\\test\\images\"\n",
    "# path_labels_valid = r\"\"\n",
    "# path_labels_test = r\"D:\\PolyPhonic\\data\\test\\labels.csv\"\n",
    "\n",
    "# class_list = [str(x) for x in range(0,150)]\n",
    "# df_training = pd.read_csv(path_labels_training,encoding='cp1252')\n",
    "# #df_valid = pd.read_csv(path_labels_training,)\n",
    "# df_test = pd.read_csv(path_labels_test,encoding='cp1252')\n",
    "\n",
    "\n",
    "# #datagenVal = ImageDataGenerator()\n",
    "# datagenTrain = ImageDataGenerator(rescale = 1./255,validation_split=0.2) ## normalising images to have pixel values of 0-1\n",
    "\n",
    "# train_generator = datagenTrain.flow_from_dataframe(\n",
    "# df_training,\n",
    "# directory=path_directory_training,\n",
    "# x_col='filename',\n",
    "# y_col=class_list,\n",
    "# batch_size= 32,\n",
    "# target_size=(100,100),\n",
    "# class_mode='raw',\n",
    "# shuffle= False,\n",
    "# color_mode ='grayscale')\n",
    "\n",
    "# validation_generator = datagenTrain.flow_from_dataframe(  ## using the same datagen generator , allowed by validation_split paramater\n",
    "# df_training,\n",
    "# directory=path_directory_training,\n",
    "# x_col='filename',\n",
    "# y_col=class_list,\n",
    "# batch_size= 32, ## how often do we want to update our NN (how large a samples before reflecting)\n",
    "# target_size=(100,100),\n",
    "# class_mode='raw',\n",
    "# shuffle= False,\n",
    "# color_mode='grayscale')\n",
    "\n",
    "\n",
    "# datagenTest = ImageDataGenerator()\n",
    "\n",
    "# test_generator = datagenTest.flow_from_dataframe(\n",
    "# df_test, \n",
    "# directory = path_directory_test,    \n",
    "# x_col = 'filename',\n",
    "# y_col = class_list,\n",
    "# class_mode = 'raw',\n",
    "# color_mode='grayscale',\n",
    "# target_size=(100,100),\n",
    "# shuffle= False,\n",
    "# batch_size = 32)\n",
    "\n",
    "# # evaluate_generator = datagenTest.flow_from_dataframe(\n",
    "# # dataframe = df_LOL,\n",
    "# # directory= r'C:\\Users\\Gebruiker\\Desktop\\test.png',\n",
    "# # batch_size= 1,\n",
    "# # target_size=(100,100),\n",
    "# # class_mode= None,\n",
    "# # shuffle= False,\n",
    "# # color_mode='grayscale')\n",
    "\n",
    "# training_steps = train_generator.n // train_generator.batch_size\n",
    "# validation_steps = validation_generator.n // validation_generator.batch_size\n",
    "# test_steps = test_generator.n // test_generator.batch_size\n",
    "# # evaluate_steps = evaluate_generator.n // evaluate_generator.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'D:\\\\PolyPhonic\\\\data\\\\validation\\\\images'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-9c9b4b1922c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mclass_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mdf_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_labels_training\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cp1252'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mdf_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_directory_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cp1252'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_labels_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cp1252'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1872\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1873\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1874\u001b[1;33m                 \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1875\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'D:\\\\PolyPhonic\\\\data\\\\validation\\\\images'"
     ]
    }
   ],
   "source": [
    "path_labels_training = r\"D:\\PolyPhonic\\data\\training\\labels.csv\"\n",
    "path_directory_training = r\"D:\\PolyPhonic\\data\\training\\images\"\n",
    "path_directory_test = r\"D:\\PolyPhonic\\data\\test\\images\"\n",
    "path_directory_valid = r\"D:\\PolyPhonic\\data\\validation\\images\"\n",
    "path_labels_valid = r\"D:\\PolyPhonic\\data\\validation\\labels.csv\"\n",
    "path_labels_test = r\"D:\\PolyPhonic\\data\\test\\labels.csv\"\n",
    "\n",
    "\n",
    "class_list = [str(x) for x in range(0,150)]\n",
    "df_training = pd.read_csv(path_labels_training,encoding='cp1252')\n",
    "df_valid = pd.read_csv(path_directory_valid,encoding='cp1252')\n",
    "df_test = pd.read_csv(path_labels_test,encoding='cp1252')\n",
    "\n",
    "\n",
    "datagenVal = ImageDataGenerator()\n",
    "datagenTrain = ImageDataGenerator(rescale = 1./255) ## normalising images to have pixel values of 0-1\n",
    "\n",
    "train_generator = datagenTrain.flow_from_dataframe(\n",
    "df_training,\n",
    "directory=path_directory_training,\n",
    "x_col='filename',\n",
    "y_col=class_list,\n",
    "batch_size= 32,\n",
    "target_size=(100,100),\n",
    "class_mode='raw',\n",
    "shuffle= False,\n",
    "color_mode ='grayscale')\n",
    "\n",
    "validation_generator = datagenVal.flow_from_dataframe(  ## using the same datagen generator , allowed by validation_split paramater\n",
    "df_training,\n",
    "directory=path_directory_training,\n",
    "x_col='filename',\n",
    "y_col=class_list,\n",
    "batch_size= 32, ## how often do we want to update our NN (how large a samples before reflecting)\n",
    "target_size=(100,100),\n",
    "class_mode='raw',\n",
    "shuffle= False,\n",
    "color_mode='grayscale')\n",
    "\n",
    "\n",
    "datagenTest = ImageDataGenerator()\n",
    "\n",
    "test_generator = datagenTest.flow_from_dataframe(\n",
    "df_test, \n",
    "directory = path_directory_test,    \n",
    "x_col = 'filename',\n",
    "y_col = class_list,\n",
    "class_mode = 'raw',\n",
    "color_mode='grayscale',\n",
    "target_size=(100,100),\n",
    "shuffle= False,\n",
    "batch_size = 32)\n",
    "\n",
    "# evaluate_generator = datagenTest.flow_from_dataframe(\n",
    "# dataframe = df_LOL,\n",
    "# directory= r'C:\\Users\\Gebruiker\\Desktop\\test.png',\n",
    "# batch_size= 1,\n",
    "# target_size=(100,100),\n",
    "# class_mode= None,\n",
    "# shuffle= False,\n",
    "# color_mode='grayscale')\n",
    "\n",
    "training_steps = train_generator.n // train_generator.batch_size\n",
    "validation_steps = validation_generator.n // validation_generator.batch_size\n",
    "test_steps = test_generator.n // test_generator.batch_size\n",
    "# evaluate_steps = evaluate_generator.n // evaluate_generator.batch_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Our data seems to be heavily unevenly distributed, notes in frets 1 - 6 are heavily preferred. (24 of the 150)\n",
    "* Sequence of 6 images (beats), batch_size = 1? stateless\n",
    "* sequence vector of CNN into RNN\n",
    "* Seems that the buildin ImageDataGenerator cannot handle CRNN (Batch,Frames,H,W,D).\n",
    "  The default ImageGenerator can only Sequence(s) of steps 1, that is (Batch,H,W,D).\n",
    "* Create a custom generator or batch_size = 8 and statefull.\n",
    "* Our sequences are the songs, and the spectograms the steps, since it is beat order that influence each other.\n",
    "\n",
    "* Perhaps no Generator is needed , our training dataset is only 500mb large, enough to hold in RAM\n",
    "* generator yields list of tuple(x,y) instead of a single x,y?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c9b5dff6e061>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "# model = Sequential()\n",
    "# model.add(layers.Conv2D(64,(3,3),activation='relu',input_shape=(100,100,1)))\n",
    "# model.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
    "# model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "# model.add(layers.Conv2D(128,(3,3),activation='relu'))\n",
    "# model.add(layers.GlobalMaxPool2D())\n",
    "\n",
    "# model.add(layers.Reshape(target_shape=(128,-1)))\n",
    "# model.add(layers.GRU(128,dropout=0.2))\n",
    "# model.add(layers.Dense(150, activation='sigmoid'))\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "# train_generator.reset()\n",
    "# validation_generator.reset()\n",
    "\n",
    "# model.compile(loss=binary_crossentropy,metrics=['accuracy'],optimizer= RMSprop())\n",
    "\n",
    "# history = model.fit_generator(generator=train_generator,\n",
    "#                     steps_per_epoch=training_steps,\n",
    "#                     epochs=1,validation_data=validation_generator,\n",
    "#                     validation_steps=validation_steps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CustomGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-4f8a7438e99b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdatagenTrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCustomGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_labels_training\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdatagenValid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCustomGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_labels_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtraining_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatagenTrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow_from_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mvalidation_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatagenValid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow_from_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CustomGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "input_tensor = layers.Input(shape=(100,100,1))\n",
    "CNN_1 = layers.Conv2D(64,kernel_size=(3,3),activation='relu')(input_tensor)\n",
    "MAX_POOLING1 = layers.MaxPooling2D(pool_size=(2,2))(CNN_1)\n",
    "CNN_2 = layers.Conv2D(64,kernel_size=(3,3),activation='relu')(MAX_POOLING1)\n",
    "MAX_POOLING2 = layers.MaxPooling2D(pool_size=(2,2))(CNN_2)\n",
    "\n",
    "FLATTEN = layers.Flatten()(MAX_POOLING2)\n",
    "\n",
    "# GRU_1 = layers.GRU(128)(MAX_POOLING3)\n",
    "OUTPUT_TENSOR = layers.Dense(150,activation='sigmoid')(FLATTEN)\n",
    "model.summary()\n",
    "model = keras.models.Model(input_tensor,OUTPUT_TENSOR)   ## aggregates layers between input_tensor and OUTPUT_TENSOR\n",
    "\n",
    "\n",
    "model.compile(loss=binary_crossentropy,metrics=['accuracy'],optimizer= RMSprop())\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=training_steps,\n",
    "                    epochs=1,validation_data=validation_generator,\n",
    "                    validation_steps=validation_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sample_weights(r'D:\\Polyphonic\\trained_models\\CRNN_version1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(r'D:\\Polyphonic\\trained_models\\CRNN_version1.h5')\n",
    "test_generator.reset()\n",
    "prediction = model.predict_generator(generator=test_generator,steps=test_steps,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_note in prediction[0]:\n",
    "    print(class_note)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_list = np.zeros(150)\n",
    "\n",
    "for row in df_training.to_numpy():\n",
    "    for index,value in enumerate(row[1:]):\n",
    "         if(value == 1.0):\n",
    "            count_list[index] += 1 \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_stringFret = {}     ## dictionary for one-hot-encoded values\n",
    "counter = 0\n",
    "for string in range(1,7):\n",
    "    for fret in range(0,25):\n",
    "        dictionary_stringFret[counter] = (string,fret)\n",
    "        counter += 1 \n",
    "dictionary_stringFret_reversed = {v: k for k, v in dictionary_stringFret.items()}\n",
    "dictionary_stringFret_reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,value in enumerate(count_list):\n",
    "    if(index)\n",
    "    print(index,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Distribution of fret position played\", fontsize=20)\n",
    "plt.ylabel('Number of times played', fontsize=18)\n",
    "plt.xlabel('fret-string position ', fontsize=18)\n",
    "\n",
    "categories = list(df_training.columns.values)\n",
    "sns.set(font_scale = 2)\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "ax= sns.barplot(categories, df_training.iloc[:,1:].sum().values)\n",
    "rects = ax.patches\n",
    "labels = df_training.iloc[:,1:].sum().values\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img,label = next(test_generator)  ##prob rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32 samples = batch_size 4 * sequences 8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
